{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d67a5-a441-4d1c-8990-eec0dfa6cc8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python ultralytics\n",
    "!pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937eec0-1e17-4127-8742-ff8780651806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Load an official Segment model from YOLOv9\n",
    "model = YOLO('yolov9e-seg.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78fb23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e987ede-90bd-4421-b09e-73d3b46d86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function for person tracking with json outputs and optional videos with annotation \n",
    "def person_tracking(video_path, person_only=True, save_video=True):\n",
    "    # open the video file\n",
    "    reader = imageio.get_reader(video_path)\n",
    "    frames = []\n",
    "    i = 0\n",
    "    all_object_data = []\n",
    "    file_name = Path(video_path).stem\n",
    "\n",
    "    for frame in reader:\n",
    "        # Convert frame from RGB (imageio's default) to BGR (OpenCV's default)\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        try:\n",
    "            # Run YOLOv9 tracking on the frame, persisting tracks between frames with bytetrack\n",
    "            conf = 0.2\n",
    "            iou = 0.5\n",
    "            results = model.track(frame_bgr, persist=True, conf=conf, iou=iou, show=False, tracker=\"bytetrack.yaml\")\n",
    "\n",
    "            # change detection results to Person pathing API output formats.\n",
    "            object_json = change_format(results[0], i, person_only)\n",
    "            all_object_data.append(object_json)\n",
    "\n",
    "            # Append the annotated frame to the frames list (for mp4 creation)\n",
    "            annotated_frame = results[0].plot()\n",
    "            frames.append(annotated_frame)\n",
    "            i += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame: {e}\")\n",
    "            break\n",
    "\n",
    "    # save the object tracking array to json file\n",
    "    with open(f'{file_name}_output.json', 'w') as file:\n",
    "        json.dump(all_object_data, file, indent=4)\n",
    "\n",
    "     # save annotated video\n",
    "    if save_video is True:\n",
    "        # Create a VideoWriter object of mp4\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        output_path = f\"output/{file_name}_annotated.mp4\"\n",
    "        fps = reader.get_meta_data()['fps']\n",
    "        frame_size = reader.get_meta_data()['size']\n",
    "        video_writer = cv2.VideoWriter(output_path, fourcc, fps, frame_size)\n",
    "\n",
    "        # Write each frame to the video and release the video writer object when done\n",
    "        for frame in frames:\n",
    "            video_writer.write(frame)\n",
    "        video_writer.release()\n",
    "        print(f\"Video saved to {output_path}\")\n",
    "\n",
    "    return all_object_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dfe34-cdfc-4857-aca8-7fdd634c1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function that changes YOLOV9 output to Person pathing API output format\n",
    "def change_format(results, ts, person_only):\n",
    "    #set person_only to True if you only want to track persons, not other objects.\n",
    "    object_json = []\n",
    "\n",
    "    for i, obj in enumerate(results.boxes):\n",
    "        x_center, y_center, width, height = obj.xywhn[0]\n",
    "        # Calculate Left and Top from center\n",
    "        left = x_center - (width / 2)\n",
    "        top = y_center - (height / 2)\n",
    "        obj_name = results.names[int(obj.cls)]\n",
    "        # Create dictionary for each object detected\n",
    "        if (person_only and obj_name == \"person\") or not person_only:\n",
    "            obj_data = {\n",
    "                obj_name: {\n",
    "                    \"BoundingBox\": {\n",
    "                        \"Height\": float(height),\n",
    "                        \"Left\": float(left),\n",
    "                        \"Top\": float(top),\n",
    "                        \"Width\": float(width)\n",
    "                    },\n",
    "                    \"Index\": int(obj.id)  # Object index\n",
    "                },\n",
    "                \"Timestamp\": ts  # timestamp of the detected object\n",
    "            }\n",
    "        object_json.append(obj_data)\n",
    "\n",
    "    return object_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c0585-6ea4-447e-82d6-46a16ef0ddfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#main function to call \n",
    "video_path = 'videoblocks-aerial-view-people-walking-down-center-lane-grocery-shopping-by-produce-sec_ryyqlpbp3__9a31ad8ce3f137b6572eefb5e6255d81__P360.mp4'\n",
    "all_object_data = person_tracking(video_path, person_only=True, save_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd74d3-18c9-42a9-b99d-acb988e0158d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
